{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a Spam classifier\n",
    "\n",
    "    - Data source from UCI Datasource repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_dataframe = pd.read_table(\n",
    "    '../input/spam_collection', header=None, encoding='utf-8')\n",
    "\n",
    "\n",
    "# Yeta column rename gare huncha, rename from 0, 1 to classes and messages ...\n",
    "classes = messages_dataframe[0]\n",
    "text_messages = messages_dataframe[1]\n",
    "classes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the data:\n",
    "\n",
    "    - Encoding it to classes. (0 -> Ham, 1 -> Spam)\n",
    "    - Removing things like email, phone numbers, links, punctuations etc etc\n",
    "    - Making everything to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "encoded_classes = encoder.fit_transform(classes)\n",
    "\n",
    "processed = text_messages.str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$',\n",
    "                                      'emailaddress')\n",
    "processed = processed.str.replace(\n",
    "    r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$', 'webaddress')\n",
    "processed = processed.str.replace(r'Â£|\\$', 'moneysymb')\n",
    "processed = processed.str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$',\n",
    "                                  'phonenumbr')\n",
    "processed = processed.str.replace(r'\\d+(\\.\\d+)?', 'numbr')\n",
    "processed = processed.str.replace(r'[^\\w\\d\\s]', ' ')\n",
    "processed = processed.str.replace(r'\\s+', ' ')\n",
    "processed = processed.str.replace(r'^\\s+|\\s+?$', '')\n",
    "processed = processed.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Stopwords:\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "processed = processed.apply(\n",
    "    lambda x: ' '.join(word for word in x.split() if word not in stop_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "processed = processed.apply(\n",
    "    lambda x: ' '.join(stemmer.stem(word) for word in x.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering:\n",
    "\n",
    "> Features haru nikalney messages bata, Hamro case ma euta word euta feature huncha ... Also , called **Feature Extraction** I think."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "all_words = []\n",
    "\n",
    "for message in processed:\n",
    "    words = word_tokenize(message)\n",
    "    for word in words:\n",
    "        all_words.append(word)\n",
    "\n",
    "all_words = FreqDist(all_words)\n",
    "\n",
    "word_features = list(all_words.keys())[:1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_features(message):\n",
    "    words = word_tokenize(message)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features[word] = (word in words)\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "messages = list(zip(processed, classes))\n",
    "seed = 1\n",
    "np.random.seed = seed\n",
    "np.random.shuffle(messages)\n",
    "\n",
    "feature_sets = [(find_features(text), label) for (text, label) in messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividing the feature set into training and testing  set:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features_train, features_test = train_test_split(\n",
    "    feature_sets, test_size=0.3, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Classifiers part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_names = [\n",
    "    'Multinomial Naive Bayes', 'SVM Linear', 'Decision Trees',\n",
    "    'K Nearest Neighbours', 'Random Forest', 'AdaBoost', 'Logistic Regressor',\n",
    "    'SGD Classifier'\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    MultinomialNB(),\n",
    "    SVC(),\n",
    "    DecisionTreeClassifier(),\n",
    "    KNeighborsClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    LogisticRegression(),\n",
    "    SGDClassifier(max_iter=100)\n",
    "]\n",
    "\n",
    "all_models = zip(classifier_names, classifiers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wrapping all models into SKLearn Classifier:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes Accuracy: 97.66746411483254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codemantra/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Linear Accuracy: 86.96172248803828\n",
      "Decision Trees Accuracy: 95.75358851674642\n",
      "K Nearest Neighbours Accuracy: 95.51435406698565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codemantra/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 97.36842105263158\n",
      "AdaBoost Accuracy: 98.02631578947368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codemantra/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regressor Accuracy: 98.20574162679426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codemantra/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Classifier Accuracy: 97.96650717703349\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "\n",
    "for name, model in all_models:\n",
    "    nltk_model = SklearnClassifier(model)\n",
    "    nltk_model.train(features_train)\n",
    "    accuracy = nltk.classify.accuracy(nltk_model, features_test) * 100\n",
    "    print(\"{} Accuracy: {}\".format(name, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Voting Classifier:\n",
    "\n",
    "> Sappai mathi ko model haru lai run garrcha, sappile vote garcha spam ho ki hoina vanera ani last ma jati dherai vote aayo tyai dincha "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier: Accuracy: 97.96650717703349\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "nltk_classifier_names = [\n",
    "    'Multinomial Naive Bayes', 'SVM Linear', 'Decision Trees',\n",
    "    'K Nearest Neighbours', 'Random Forest', 'AdaBoost', 'Logistic Regressor',\n",
    "    'SGD Classifier'\n",
    "]\n",
    "\n",
    "nltk_classifiers = [\n",
    "    MultinomialNB(),\n",
    "    SVC(kernel='linear'),\n",
    "    DecisionTreeClassifier(),\n",
    "    KNeighborsClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    LogisticRegression(),\n",
    "    SGDClassifier(max_iter=100)\n",
    "]\n",
    "\n",
    "nltk_all_models = list(zip(nltk_classifier_names, nltk_classifiers))\n",
    "\n",
    "vote_holder = SklearnClassifier(\n",
    "    VotingClassifier(estimators=nltk_all_models, voting='hard', n_jobs=-1))\n",
    "vote_holder.train(features_train)\n",
    "\n",
    "accuracy = nltk.classify.accuracy(nltk_model, features_test) * 100\n",
    "print(\"Voting Classifier: Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playing Around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      1.00      0.99      1451\n",
      "        spam       0.98      0.89      0.93       221\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1672\n",
      "   macro avg       0.98      0.94      0.96      1672\n",
      "weighted avg       0.98      0.98      0.98      1672\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">actual</th>\n",
       "      <th>ham</th>\n",
       "      <td>1448</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>25</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            predicted     \n",
       "                  ham spam\n",
       "actual ham       1448    3\n",
       "       spam        25  196"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features, test_labels = zip(*features_test)\n",
    "\n",
    "prediction = vote_holder.classify_many(test_features)\n",
    "\n",
    "print(classification_report(test_labels, prediction))\n",
    "\n",
    "pd.DataFrame(\n",
    "    confusion_matrix(test_labels, prediction),\n",
    "    index = [['actual', 'actual'], ['ham', 'spam']],\n",
    "    columns = [['predicted', 'predicted'], ['ham', 'spam']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
